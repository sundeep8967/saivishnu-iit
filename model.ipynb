{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 22:50:23.542531: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-08 22:50:23.545726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-08 22:50:23.545737: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vishnu/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('files/embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vector'] = df['CarNewsTitle'] + df['Highlights'] + df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CarNewsTitle', 'Highlights', 'Description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df, how='cross')\n",
    "df = df[['CarNewsId_x', 'CarNewsId_y', 'vector_x', 'vector_y']]\n",
    "df.rename(columns={'CarNewsId_x':'id1', 'CarNewsId_y':'id2', 'vector_x':'vector_1', 'vector_y':'vector_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random100_s1 = [3,8,34,43,44,45,50,53,56,59,62,65,67,69,71,91,118,123,128,134,137,138,176,188,194,196,201,207,214,218,229,243,248,257,267,268,276,298,301,315,316,321,325,329,333,349,357,379,389,411,428,452,469,474,490,514,526,528,541,556,562,565,572,575,580,583,600,622,624,630,640,648,682,683,706,707,717,720,729,732,738,739,743,753,760,761,762,767,777,818,837,838,845,846,848,852,856,862,874,876]\n",
    "random100_s2 = [22,25,27,42,49,54,55,76,93,94,96,97,120,150,163,173,186,189,195,204,208,209,212,221,227,242,251,255,262,265,266,272,287,302,305,310,318,331,345,372,373,383,391,398,408,424,433,434,435,454,456,459,473,475,479,480,496,501,502,510,540,545,560,574,590,606,612,623,669,681,689,695,721,726,727,731,737,756,766,779,786,792,794,798,799,802,815,817,821,823,828,829,831,842,850,858,859,866,867,873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s1 = pd.read_csv('files/top15_simdesc_cleanedsample1.csv')\n",
    "df_s2 = pd.read_csv('files/top15_simdesc_cleanedsample2.csv')\n",
    "df_s = pd.concat([df_s1, df_s2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df, df_s, on=['id1','id2'])\n",
    "df2 = df2[['id1','id2','vector_1','vector_2','classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>vector_1</th>\n",
       "      <th>vector_2</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28032</td>\n",
       "      <td>28214</td>\n",
       "      <td>[[-0.22375138100000003, 0.4476603866, 0.236245...</td>\n",
       "      <td>[[0.307490617, 0.0315352827, 0.4327310026, 0.7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28032</td>\n",
       "      <td>28221</td>\n",
       "      <td>[[-0.22375138100000003, 0.4476603866, 0.236245...</td>\n",
       "      <td>[[-0.6250770688, 0.4015112817, 0.8460243940000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28032</td>\n",
       "      <td>28314</td>\n",
       "      <td>[[-0.22375138100000003, 0.4476603866, 0.236245...</td>\n",
       "      <td>[[-0.1413342953, 1.1729570627, 0.3858661652, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28032</td>\n",
       "      <td>28315</td>\n",
       "      <td>[[-0.22375138100000003, 0.4476603866, 0.236245...</td>\n",
       "      <td>[[-0.1413342953, 1.1729570627, 0.3858661652, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28032</td>\n",
       "      <td>28376</td>\n",
       "      <td>[[-0.22375138100000003, 0.4476603866, 0.236245...</td>\n",
       "      <td>[[1.1202390194, 0.7119821906, -0.0169125833, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>29087</td>\n",
       "      <td>28955</td>\n",
       "      <td>[[-1.3961848021, 0.39991816880000003, -0.68192...</td>\n",
       "      <td>[[-1.0581085682, 0.5650228858, 0.3123189211000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>29087</td>\n",
       "      <td>28964</td>\n",
       "      <td>[[-1.3961848021, 0.39991816880000003, -0.68192...</td>\n",
       "      <td>[[-1.3613573313, 0.8344203830000001, 0.1985223...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>29087</td>\n",
       "      <td>29028</td>\n",
       "      <td>[[-1.3961848021, 0.39991816880000003, -0.68192...</td>\n",
       "      <td>[[0.044806093000000005, 0.7397106886, -0.43723...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>29087</td>\n",
       "      <td>29037</td>\n",
       "      <td>[[-1.3961848021, 0.39991816880000003, -0.68192...</td>\n",
       "      <td>[[-1.6479408741000001, 0.4668063223, -0.623096...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>29087</td>\n",
       "      <td>29038</td>\n",
       "      <td>[[-1.3961848021, 0.39991816880000003, -0.68192...</td>\n",
       "      <td>[[-1.1884791851, 0.21047014, -0.2608771622, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id1    id2                                           vector_1  \\\n",
       "0     28032  28214  [[-0.22375138100000003, 0.4476603866, 0.236245...   \n",
       "1     28032  28221  [[-0.22375138100000003, 0.4476603866, 0.236245...   \n",
       "2     28032  28314  [[-0.22375138100000003, 0.4476603866, 0.236245...   \n",
       "3     28032  28315  [[-0.22375138100000003, 0.4476603866, 0.236245...   \n",
       "4     28032  28376  [[-0.22375138100000003, 0.4476603866, 0.236245...   \n",
       "...     ...    ...                                                ...   \n",
       "2995  29087  28955  [[-1.3961848021, 0.39991816880000003, -0.68192...   \n",
       "2996  29087  28964  [[-1.3961848021, 0.39991816880000003, -0.68192...   \n",
       "2997  29087  29028  [[-1.3961848021, 0.39991816880000003, -0.68192...   \n",
       "2998  29087  29037  [[-1.3961848021, 0.39991816880000003, -0.68192...   \n",
       "2999  29087  29038  [[-1.3961848021, 0.39991816880000003, -0.68192...   \n",
       "\n",
       "                                               vector_2  classification  \n",
       "0     [[0.307490617, 0.0315352827, 0.4327310026, 0.7...               0  \n",
       "1     [[-0.6250770688, 0.4015112817, 0.8460243940000...               0  \n",
       "2     [[-0.1413342953, 1.1729570627, 0.3858661652, -...               0  \n",
       "3     [[-0.1413342953, 1.1729570627, 0.3858661652, -...               0  \n",
       "4     [[1.1202390194, 0.7119821906, -0.0169125833, -...               0  \n",
       "...                                                 ...             ...  \n",
       "2995  [[-1.0581085682, 0.5650228858, 0.3123189211000...               0  \n",
       "2996  [[-1.3613573313, 0.8344203830000001, 0.1985223...               0  \n",
       "2997  [[0.044806093000000005, 0.7397106886, -0.43723...               0  \n",
       "2998  [[-1.6479408741000001, 0.4668063223, -0.623096...               0  \n",
       "2999  [[-1.1884791851, 0.21047014, -0.2608771622, -0...               0  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(['id1','id2','classification'], axis=1).values\n",
    "y = df2.iloc[:,-1:].values\n",
    "_, m = X.shape\n",
    "_, n = y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "epochs = 50\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,m], name='Input')\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n], name='Output')\n",
    "\n",
    "W = tf.Variable(tf.zeros([m,n]))\n",
    "b = tf.Variable(tf.zeros([n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "Y_hat = tf.nn.sigmoid(tf.add(tf.matmul(X,W),b))\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Y_hat,labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 22:52:16.803321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-08 22:52:16.803346: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-08 22:52:16.803367: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cssaivishnu): /proc/driver/nvidia/version does not exist\n",
      "2022-06-08 22:52:16.803616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 22:52:16.805167: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Input:0\", shape=(?, 2), dtype=float32) which was passed to the argument `feed_dict` with key Tensor(\"Input:0\", shape=(?, 2), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     cost_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     _, c \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mX\u001b[49m\u001b[43m:\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     correct_prediction \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mequal(tf\u001b[38;5;241m.\u001b[39mround(Y_hat), Y)\n\u001b[1;32m      9\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mcast(correct_prediction,tf\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py:1138\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1134\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1135\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot interpret feed_dict key as Tensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subfeed_val, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m-> 1138\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1139\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe value of a feed cannot be a tf.Tensor object. Acceptable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1140\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeed values include Python scalars, strings, lists, numpy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1141\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarrays, or TensorHandles. For reference, the tensor object \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1142\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwas \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(feed_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which was passed to the argument \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1143\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`feed_dict` with key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(feed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1145\u001b[0m subfeed_dtype \u001b[38;5;241m=\u001b[39m subfeed_t\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mas_numpy_dtype\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subfeed_val, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _convert_to_numpy_obj(\n\u001b[1;32m   1147\u001b[0m     subfeed_dtype, subfeed_val) \u001b[38;5;241m!=\u001b[39m subfeed_val:\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Input:0\", shape=(?, 2), dtype=float32) which was passed to the argument `feed_dict` with key Tensor(\"Input:0\", shape=(?, 2), dtype=float32)."
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    cost_history, accuracy_history = [], []\n",
    "    for epoch in range(epochs):\n",
    "        cost_per_epoch = 0\n",
    "        _, c = sess.run([optimizer,cost], feed_dict={X:X,Y:y})\n",
    "        correct_prediction = tf.equal(tf.round(Y_hat), Y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        cost_history.append(c)\n",
    "        accuracy_history.append(accuracy.eval({X:X,Y:y})*100)\n",
    "        if (epoch+1)% display_step == 0 and epoch != 0:\n",
    "            print('Epoch: {4.0f} - Cost: {0.5f} - Acc: {0.5f}'.format(epoch+1,c,accuracy_history[-1]))\n",
    "    Weight = sess.run(W)\n",
    "    Bias = sess.run(b)\n",
    "    correct_prediction = tf.equal(tf.arg_max(Y_hat,1),tf.arg_max(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print('\\nAccuracy:', accuracy_history[-1], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(['id1','id2','classification'], axis=1).values\n",
    "y = df2.iloc[:,-1:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, m = X_train.shape\n",
    "_, n = y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "epochs = 50\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,m], name='Input')\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n], name='Output')\n",
    "\n",
    "W = tf.Variable(tf.zeros([m,n]))\n",
    "b = tf.Variable(tf.zeros([n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "Y_hat = tf.nn.sigmoid(tf.add(tf.matmul(X,W),b))\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Y_hat,labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    cost_history, accuracy_history = [], []\n",
    "    for epoch in range(epochs):\n",
    "        cost_per_epoch = 0\n",
    "#        sess.run(optimizer, feed_dict={X:X_train,Y:y_train})\n",
    "        _, c = sess.run([cost,optimizer], feed_dict={X:X_train,Y:y_train})\n",
    "        correct_prediction = tf.equal(tf.round(Y_hat), Y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        cost_history.append(c)\n",
    "        accuracy_history.append(accuracy.eval({X:X_train,Y:y_train})*100)\n",
    "        if (epoch+1)% display_step == 0 and epoch != 0:\n",
    "            print('Epoch: {4.0f} - Cost: {0.5f} - Acc: {0.5f}'.format(epoch+1,c,accuracy_history[-1]))\n",
    "    Weight = sess.run(W)\n",
    "    Bias = sess.run(b)\n",
    "    correct_prediction = tf.equal(tf.arg_max(Y_hat,1),tf.arg_max(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print('\\nAccuracy:', accuracy_history[-1], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
